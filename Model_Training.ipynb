{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caeb5126",
   "metadata": {},
   "source": [
    "## Model Training for Real Time Communication through AI for Specially Abled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d217477",
   "metadata": {},
   "source": [
    "### Loading the Dataset & Image Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d28c672e-2adf-48d4-a932-9eead3615484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59fd6cd1-d07f-4142-9fb5-ad8b39e4d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Datagen\n",
    "train_datagen = ImageDataGenerator(rescale=1/255,zoom_range=0.2,horizontal_flip=True,vertical_flip=False)\n",
    "# Testing Datagen\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb15498-7081-4159-8bc2-9446325480b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15750 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training Dataset\n",
    "x_train=train_datagen.flow_from_directory(r'Dataset\\training_set',target_size=(64,64), class_mode='categorical',batch_size=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68532a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2250 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test Dataset\n",
    "x_test=test_datagen.flow_from_directory(r'Dataset\\test_set',target_size=(64,64), class_mode='categorical',batch_size=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d51502-6c7f-481f-93d1-fbbf8d4b8312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len x-train :  18\n",
      "Len x-test :  3\n"
     ]
    }
   ],
   "source": [
    "print(\"Len x-train : \", len(x_train))\n",
    "print(\"Len x-test : \", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c7bd1a5-f00c-4e38-8b2b-7d72b87c8342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587735d2-c2e1-41d9-9977-c2cc95d292d1",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce455129-151f-4d93-b620-f9db2406426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c153d655-bf2a-4736-86b6-ec89a4e165c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e37f026-48f0-4ce0-93c5-03c15d18c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Layers\n",
    "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "# Adding Hidden Layers\n",
    "model.add(Dense(300,activation='relu'))\n",
    "model.add(Dense(150,activation='relu'))\n",
    "\n",
    "# Adding Output Layer\n",
    "model.add(Dense(9,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29f8b091-69b3-4fea-b6d4-6ea92c4fb717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the Model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b534c848-a41a-4332-af56-332b8ae63065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 130s 7s/step - loss: 0.5844 - accuracy: 0.8272 - val_loss: 0.2962 - val_accuracy: 0.9147\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 62s 3s/step - loss: 0.1744 - accuracy: 0.9497 - val_loss: 0.2520 - val_accuracy: 0.9387\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 446s 26s/step - loss: 0.0795 - accuracy: 0.9788 - val_loss: 0.2198 - val_accuracy: 0.9604\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 62s 3s/step - loss: 0.0398 - accuracy: 0.9900 - val_loss: 0.2082 - val_accuracy: 0.9702\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 61s 3s/step - loss: 0.0238 - accuracy: 0.9942 - val_loss: 0.2226 - val_accuracy: 0.9702\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 61s 3s/step - loss: 0.0160 - accuracy: 0.9970 - val_loss: 0.2169 - val_accuracy: 0.9756\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 62s 3s/step - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.2257 - val_accuracy: 0.9756\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 119s 7s/step - loss: 0.0080 - accuracy: 0.9989 - val_loss: 0.2496 - val_accuracy: 0.9751\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 61s 3s/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 0.2951 - val_accuracy: 0.9760\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 62s 3s/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.3119 - val_accuracy: 0.9756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15af42bc490>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Generator\n",
    "model.fit(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad001b-c47a-4d0b-9cdb-d085afd83383",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "952eca53-e5aa-4ad5-a868-5fd34080eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('aslmodel_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99428b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f0f97fd6c5ecc85c2cf8f5e01f5fe1d66323d0c47c6f4b81bd3f87b7ad3ebb6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
